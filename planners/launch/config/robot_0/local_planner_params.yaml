RRTDMPPlanner:
  robot_radius: [3, 3, 3]
  goal_tolerance: [1, 1, 1]
  path_tolerance: [50, 50, 50]
  path_checkpoint_resolution: [1, 1, 1] # do not change
  obstacle_inflation_radius: [1, 1, 1]
  time_step: [0.75, 0.50, 0.75]
  num_step: [3, 3, 3]
  linear_velocity_max: [1.0, 1.0, 1.0]
  angular_velocity_max: [0.5, 0.8, 0.5]
  linear_velocity_min: [0.5, 0.5, 0.5]
  angular_velocity_min: [0.0, 0.0, 0.0]
  motion_primitive_resolution: [1, 1, 1] # odd numbers work best
  max_iterations: [150, 150, 150]
  controller_frequency: [10.0, 10.0, 10.0]
  local_costmap_border: [false, false, false]
  forward_bias: [5, 5, 5]
  velocity_topic: "cmd_vel"
  rule_offset: [20.0, 20.0, 20.0]
  goal_offset: [0.0, 0.0, 0.0]
  person_offset: [0.0, 0.0, 0.0] # the number of cells where force begins to be applied //80.0
  rule_scale: [5.0, 5.0, 5.0]
  goal_scale: [30.0, 30.0, 30.0]
  person_scale: [30.0, 30.0, 30.0] # 0.5
  mp_range_scale: [0.05, 0.05, 0.05]
  stop_loops: [3, 3, 3]
  rule_weight: [0.75, 0.50, 0.75]
  goal_weight: [1.75, 1.50, 1.75]
  person_weight: [0.50, 1.00, 0.50]
  avoid_ang: [-0.2, -0.2, -0.2] # -0.1 worked, -0.2 worked better
  p_dist_weight: [1.5, 1.5, 1.5]
  p_ang_weight: [0.5, 0.5, 0.5]
  tilt_bias: [2.355, 2.355, 2.355] #0.785rad is 45deg
  linear_acceleration_max: [1.0, 1.0, 1.0]
  angular_acceleration_max: [0.8, 1.0, 0.8]
  rule_max: [35.0, 35.0, 35.0] # 3[m]/0.075[m/cell] - 10[cell]
  goal_max: [45.0, 45.0, 45.0] # 3[m]/0.075[m/cell]
  person_max: [5.0, 5.0, 5.0] # 2[m/s]
  failures_max: [3.0, 3.0, 3.0]
  carlike: [true, true, true]
